{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ciril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ciril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ciril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ciril\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import inflect\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.getcwd() + \"\\\\\" + \"nlp-lab-dm23/train_processed.csv\")\n",
    "test_df = pd.read_csv(os.getcwd() + \"\\\\\" + \"nlp-lab-dm23/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = inflect.engine()\n",
    "\n",
    "def lowercase_text(text):\n",
    "  return text.lower()\n",
    "\n",
    "def remove_nums(text):\n",
    "  return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def replace_nums(text):\n",
    "  # split strings into list of texts\n",
    "  temp_string = text.split()\n",
    "  # initialise empty list\n",
    "  new_str = []\n",
    "\n",
    "  for word in temp_string:\n",
    "      # if text is a digit, convert the digit\n",
    "      # to numbers and append into the new_str list\n",
    "      if word.isdigit():\n",
    "          temp = q.number_to_words(word)\n",
    "          new_str.append(temp)\n",
    "      # append the texts as it is\n",
    "      else:\n",
    "          new_str.append(word)\n",
    "\n",
    "  # join the texts of new_str to form a string\n",
    "  temp_str = ' '.join(new_str)\n",
    "  return temp_str\n",
    "\n",
    "def remove_punct(text):\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(translator)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words(\"english\"))\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "  return filtered_text\n",
    "\n",
    "def full_preprocessing_pipeline(df: DataFrame):\n",
    "  res = []\n",
    "  for i, row in tqdm(df.iterrows()):\n",
    "    res.append(\n",
    "      remove_stopwords(\n",
    "        remove_punct(\n",
    "          remove_nums(\n",
    "            lowercase_text(\n",
    "                row[2]\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000it [00:45, 2625.90it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = full_preprocessing_pipeline(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard',\n",
       " 'overstate',\n",
       " 'sense',\n",
       " 'shock',\n",
       " 'across',\n",
       " 'much',\n",
       " 'europe',\n",
       " 'popular',\n",
       " 'mandate',\n",
       " 'americans',\n",
       " 'given',\n",
       " 'george',\n",
       " 'w',\n",
       " 'bush',\n",
       " 'even',\n",
       " 'result',\n",
       " 'great',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [15:25<00:00, 129.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(texts):\n",
    "  stemmed_text = []\n",
    "  for text in tqdm(texts):\n",
    "    stemmed_text.append([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text])\n",
    "  return stemmed_text\n",
    "texts_lem = lemmatize_words(preprocessed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(text):\n",
    "    t = remove_stopwords(\n",
    "        remove_punct(\n",
    "          remove_nums(\n",
    "            lowercase_text(\n",
    "                text\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in t])\n",
    "\n",
    "train_df[\"Description\"] = train_df[\"Description\"].apply(lambda x: preprocess_sample(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We Have To Talk</td>\n",
       "      <td>hard overstate sense shock across much europe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Boss, Pedro talk shop</td>\n",
       "      <td>sometimes george steinbrenner negotiate tuesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Crawford leads way as US goes 1-2-3 in 200m</td>\n",
       "      <td>finish partisan greek crowd want see shawn cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Ajax Amsterdam 0-1 Juventus: FT Report</td>\n",
       "      <td>amsterdam september champion league moment bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Krispy Kreme SEC probe widens</td>\n",
       "      <td>krispy kreme doughnut inc say friday inform se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>2</td>\n",
       "      <td>A bit of a head-scratcher</td>\n",
       "      <td>many professional league recently defend champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Fans Learning to Make Do Without NHL (AP)</td>\n",
       "      <td>ap nhl disappear right eye reason simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Can Arroyo help Red Sox finally get a win?</td>\n",
       "      <td>curt schilling pedro martinez bring boston red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Woods May Stay No. 1 - for Now (AP)</td>\n",
       "      <td>ap stewart cink atop leaderboard david tom lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>1</td>\n",
       "      <td>Mixed reaction to killing of Veerappan</td>\n",
       "      <td>chennai oct pti kill forest brigand veerappan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index                                        Title  \\\n",
       "0                 1                              We Have To Talk   \n",
       "1                 2                        Boss, Pedro talk shop   \n",
       "2                 2  Crawford leads way as US goes 1-2-3 in 200m   \n",
       "3                 2       Ajax Amsterdam 0-1 Juventus: FT Report   \n",
       "4                 3                Krispy Kreme SEC probe widens   \n",
       "...             ...                                          ...   \n",
       "119995            2                    A bit of a head-scratcher   \n",
       "119996            2    Fans Learning to Make Do Without NHL (AP)   \n",
       "119997            2   Can Arroyo help Red Sox finally get a win?   \n",
       "119998            2          Woods May Stay No. 1 - for Now (AP)   \n",
       "119999            1       Mixed reaction to killing of Veerappan   \n",
       "\n",
       "                                              Description  \n",
       "0       hard overstate sense shock across much europe ...  \n",
       "1       sometimes george steinbrenner negotiate tuesda...  \n",
       "2       finish partisan greek crowd want see shawn cra...  \n",
       "3       amsterdam september champion league moment bri...  \n",
       "4       krispy kreme doughnut inc say friday inform se...  \n",
       "...                                                   ...  \n",
       "119995  many professional league recently defend champ...  \n",
       "119996           ap nhl disappear right eye reason simple  \n",
       "119997  curt schilling pedro martinez bring boston red...  \n",
       "119998  ap stewart cink atop leaderboard david tom lea...  \n",
       "119999  chennai oct pti kill forest brigand veerappan ...  \n",
       "\n",
       "[120000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[\"Class Index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # \"cuda:0\" if torch.cuda.is_available() else \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df.Description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  hard overstate sense shock across much europe popular mandate american give george w bush even result great surprise\n",
      "Tokenized:  ['hard', 'overs', '##tate', 'sense', 'shock', 'across', 'much', 'europe', 'popular', 'mandate', 'american', 'give', 'george', 'w', 'bush', 'even', 'result', 'great', 'surprise']\n",
      "Token IDs:  [2524, 15849, 12259, 3168, 5213, 2408, 2172, 2885, 2759, 11405, 2137, 2507, 2577, 1059, 5747, 2130, 2765, 2307, 4474]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', texts[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(texts[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  211\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in texts:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciril\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  hard overstate sense shock across much europe popular mandate american give george w bush even result great surprise\n",
      "Token IDs: tensor([  101,  2524, 15849, 12259,  3168,  5213,  2408,  2172,  2885,  2759,\n",
      "        11405,  2137,  2507,  2577,  1059,  5747,  2130,  2765,  2307,  4474,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every tweet...\n",
    "for text in texts:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "labels = torch.tensor(train_labels).to(device)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96,000 training samples\n",
      "24,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "#val_size = int(0.2 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertTextClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertTextClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        # print(outputs)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Пример создания модели\n",
    "num_classes = 4\n",
    "model = BertTextClassifier(model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTextClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 0 / 1 ========\n",
      " Run train...\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-3.9894e-01,  1.6967e-01,  4.0876e-01,  ..., -4.0943e-01,\n",
      "           2.3090e-01, -1.8144e-01],\n",
      "         [-3.3319e-01, -9.2961e-02,  4.2549e-01,  ..., -4.0304e-01,\n",
      "          -5.2819e-01, -1.4318e+00],\n",
      "         [-1.2393e+00, -1.1252e+00,  4.0581e-01,  ..., -5.9366e-02,\n",
      "          -2.9004e-02,  5.6807e-01],\n",
      "         ...,\n",
      "         [-1.0705e-02, -2.4713e-01,  6.2462e-01,  ...,  2.9314e-01,\n",
      "          -4.4637e-02,  1.9462e-01],\n",
      "         [-3.2231e-01,  2.3992e-02,  5.0950e-01,  ..., -3.8265e-01,\n",
      "           1.0623e-01,  3.8347e-01],\n",
      "         [-3.5926e-01, -4.2509e-02,  4.7702e-01,  ..., -2.9332e-01,\n",
      "          -8.3375e-02,  2.1990e-01]],\n",
      "\n",
      "        [[-3.1342e-01,  1.7539e-01,  2.2633e-01,  ..., -2.4062e-01,\n",
      "           2.8576e-01,  1.3794e-01],\n",
      "         [-2.7924e-02,  2.9835e-01,  3.9161e-01,  ..., -3.1312e-01,\n",
      "          -1.9295e-01, -6.0143e-01],\n",
      "         [-1.3553e-01,  2.4253e-02,  5.3023e-01,  ..., -2.4209e-01,\n",
      "           9.3974e-02, -7.0108e-01],\n",
      "         ...,\n",
      "         [ 1.0251e-01, -1.1900e-01,  3.2013e-01,  ..., -3.5934e-02,\n",
      "          -5.4057e-02,  2.7543e-01],\n",
      "         [-2.3860e-01, -3.9145e-01, -7.0323e-02,  ...,  3.9226e-01,\n",
      "           2.6494e-01,  3.9047e-02],\n",
      "         [ 1.6869e-01, -1.7370e-02,  2.1856e-01,  ..., -3.6273e-02,\n",
      "           8.3229e-02,  1.4830e-01]],\n",
      "\n",
      "        [[-1.6986e-01, -3.6792e-01,  1.4612e-01,  ..., -3.1432e-01,\n",
      "           2.8928e-01, -1.3120e-01],\n",
      "         [ 5.2696e-02,  8.3950e-03, -1.6615e-02,  ...,  2.9004e-02,\n",
      "           6.0508e-01,  8.4871e-03],\n",
      "         [-2.7993e-01, -3.8828e-01, -6.0358e-02,  ..., -7.0725e-01,\n",
      "          -7.2821e-02, -5.6965e-01],\n",
      "         ...,\n",
      "         [-2.8259e-01, -3.3183e-01,  4.3020e-01,  ..., -6.6595e-02,\n",
      "           1.4273e-01, -9.9715e-02],\n",
      "         [-2.8525e-01, -3.9464e-01,  5.6089e-01,  ..., -1.4474e-01,\n",
      "           1.5737e-01, -1.0970e-01],\n",
      "         [-2.4971e-01, -4.4218e-01,  4.4253e-01,  ..., -4.7183e-02,\n",
      "           1.5076e-01, -1.0968e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1504e-01,  5.2588e-02,  5.6818e-01,  ..., -1.2570e-01,\n",
      "           3.1539e-01,  3.5706e-01],\n",
      "         [ 3.9898e-01, -2.1484e-01,  1.0713e+00,  ...,  1.2056e-01,\n",
      "           4.8102e-01,  8.2840e-01],\n",
      "         [-5.5869e-01,  3.9285e-01,  9.1176e-01,  ...,  6.4263e-02,\n",
      "           1.7631e-01, -3.7517e-01],\n",
      "         ...,\n",
      "         [-7.6262e-03,  1.0781e-01,  6.4989e-01,  ..., -5.8339e-02,\n",
      "           1.9625e-01, -6.1221e-02],\n",
      "         [ 7.6427e-02,  2.5525e-01,  5.8080e-01,  ..., -1.8889e-01,\n",
      "           2.6090e-01, -4.4900e-02],\n",
      "         [ 9.0681e-02,  2.0095e-01,  6.4214e-01,  ..., -1.0209e-01,\n",
      "           1.2845e-01,  1.4475e-02]],\n",
      "\n",
      "        [[-4.7031e-01, -4.7184e-02, -2.4764e-01,  ..., -1.2278e-01,\n",
      "           3.9886e-01,  9.9923e-02],\n",
      "         [ 1.1961e-02,  9.2897e-02, -3.2471e-01,  ..., -2.1278e-01,\n",
      "           2.2040e-01,  2.3933e-01],\n",
      "         [-2.2849e-01, -1.0855e-01, -2.8314e-01,  ..., -3.7205e-01,\n",
      "           2.1165e-01, -1.5708e-01],\n",
      "         ...,\n",
      "         [-9.4187e-03, -1.2275e-01,  2.8178e-01,  ...,  6.3738e-02,\n",
      "           5.8367e-04, -3.1387e-01],\n",
      "         [ 4.7881e-01, -1.4877e-02,  1.4475e-01,  ..., -1.3450e-01,\n",
      "          -2.5089e-01, -2.1867e-01],\n",
      "         [ 1.6266e-01,  8.5868e-02,  4.1680e-01,  ...,  8.6910e-02,\n",
      "           2.5304e-02, -1.3807e-01]],\n",
      "\n",
      "        [[-2.2013e-02, -3.7940e-02,  3.7842e-01,  ..., -8.7594e-02,\n",
      "           1.7924e-01,  3.8493e-01],\n",
      "         [ 2.6553e-01, -6.3548e-01,  3.9255e-01,  ..., -1.5064e-01,\n",
      "           2.3510e-01, -5.5889e-01],\n",
      "         [ 1.7369e-01, -7.2097e-03,  2.7021e-01,  ..., -6.0272e-01,\n",
      "          -3.6782e-01, -4.8025e-01],\n",
      "         ...,\n",
      "         [ 2.7916e-01, -1.1791e-01,  3.6235e-01,  ...,  2.1986e-01,\n",
      "           4.8912e-02,  5.9027e-02],\n",
      "         [ 9.8361e-02, -3.6284e-02,  4.1828e-01,  ...,  8.0195e-02,\n",
      "           1.0569e-01,  1.0503e-02],\n",
      "         [ 3.1028e-01, -2.6082e-01,  1.6948e-01,  ...,  2.1791e-01,\n",
      "           9.7240e-02, -3.6772e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7346, -0.2177,  0.1622,  ...,  0.1666, -0.4598,  0.7142],\n",
      "        [-0.7496, -0.3678,  0.1557,  ...,  0.4133, -0.5863,  0.8343],\n",
      "        [-0.6799, -0.1563,  0.4101,  ...,  0.2800, -0.4081,  0.8247],\n",
      "        ...,\n",
      "        [-0.8050, -0.2564,  0.0699,  ...,  0.3029, -0.5515,  0.7774],\n",
      "        [-0.7759, -0.3805, -0.6103,  ...,  0.0385, -0.5392,  0.7789],\n",
      "        [-0.8453, -0.4134, -0.5082,  ..., -0.2161, -0.6398,  0.8414]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3000 [00:03<3:07:25,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4496,  0.4914,  0.3827,  ..., -0.8102,  0.2032,  0.3080],\n",
      "         [-0.1956,  0.5607, -0.0176,  ..., -0.7040,  0.2632,  0.3675],\n",
      "         [-0.1311,  0.7139,  0.2514,  ..., -0.4234,  0.1726,  0.2230],\n",
      "         ...,\n",
      "         [-0.4228,  0.6145,  0.3387,  ..., -0.4881,  0.3812,  0.3442],\n",
      "         [-0.4831,  0.7015,  0.4284,  ..., -0.5731,  0.3099,  0.3518],\n",
      "         [-0.4086,  0.6216,  0.0813,  ..., -0.6994,  0.3641,  0.3581]],\n",
      "\n",
      "        [[-0.8152,  0.6602,  0.1574,  ..., -0.6118,  0.4040,  0.2974],\n",
      "         [-0.4668,  0.6424,  0.4994,  ..., -0.7978,  0.6254,  0.2586],\n",
      "         [-0.6807,  0.5749,  0.2690,  ..., -0.3177,  0.5856,  0.1904],\n",
      "         ...,\n",
      "         [-0.5162,  0.4485,  0.3183,  ..., -0.7389,  0.6072,  0.3887],\n",
      "         [-0.7303,  0.4924,  0.4599,  ..., -0.4797,  0.5398,  0.2308],\n",
      "         [-0.6482,  0.6335,  0.2340,  ..., -0.6696,  0.5809,  0.1585]],\n",
      "\n",
      "        [[-0.3419,  0.3441,  0.2800,  ..., -0.6394,  0.2339,  0.4639],\n",
      "         [-0.3367,  0.4584,  0.4149,  ..., -0.6490,  0.4451,  0.5456],\n",
      "         [-0.3445,  0.4721,  0.2818,  ..., -0.3228,  0.3159,  0.3540],\n",
      "         ...,\n",
      "         [-0.4331,  0.2693,  0.0045,  ..., -0.7988,  0.1993,  0.1570],\n",
      "         [-0.4181,  0.4639,  0.3725,  ..., -0.5782,  0.4226,  0.2880],\n",
      "         [-0.3901,  0.3507,  0.1113,  ..., -0.4623,  0.3172,  0.3193]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6115,  0.3192,  0.1145,  ..., -0.7024,  0.4701,  0.4289],\n",
      "         [-0.5495,  0.3350,  0.2971,  ..., -0.8724,  0.4666,  0.4080],\n",
      "         [-0.4024,  0.5522,  0.3234,  ..., -0.6916,  0.5015,  0.3828],\n",
      "         ...,\n",
      "         [-0.7233,  0.7785, -0.1055,  ..., -0.8322,  0.3121,  0.2946],\n",
      "         [-0.7105,  0.6500,  0.0916,  ..., -0.8277,  0.5731,  0.4505],\n",
      "         [-0.4877,  0.6060,  0.1628,  ..., -0.5297,  0.2210,  0.2494]],\n",
      "\n",
      "        [[-0.5606,  0.4702,  0.1203,  ..., -0.7423,  0.3831,  0.1764],\n",
      "         [-0.6028,  0.4162,  0.3493,  ..., -0.7961,  0.5386,  0.4310],\n",
      "         [-0.5138,  0.4856,  0.2718,  ..., -0.7445,  0.4223,  0.3763],\n",
      "         ...,\n",
      "         [-0.7158,  0.8050,  0.2371,  ..., -0.7775,  0.5171,  0.2220],\n",
      "         [-0.6679,  0.7202,  0.0748,  ..., -0.7387,  0.4574,  0.2335],\n",
      "         [-0.7100,  0.2545,  0.0880,  ..., -0.6030,  0.3745,  0.2250]],\n",
      "\n",
      "        [[-0.5328,  0.3847,  0.1220,  ..., -0.7222,  0.2297,  0.3087],\n",
      "         [-0.3401,  0.5827,  0.6478,  ..., -0.6997,  0.3967,  0.2744],\n",
      "         [-0.4916,  0.5201,  0.2363,  ..., -0.7877,  0.4066,  0.2840],\n",
      "         ...,\n",
      "         [-0.4018,  0.4378,  0.4320,  ..., -0.6727,  0.4533,  0.2736],\n",
      "         [-0.4386,  0.5457,  0.3624,  ..., -0.3671,  0.3798,  0.3202],\n",
      "         [-0.4281,  0.4891,  0.3616,  ..., -0.7490,  0.5216,  0.3927]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7991, -0.1266,  0.3652,  ..., -0.6724, -0.2488,  0.8798],\n",
      "        [-0.7995, -0.1245,  0.2743,  ..., -0.5909, -0.1395,  0.8446],\n",
      "        [-0.7604, -0.1739,  0.0469,  ..., -0.7647, -0.2059,  0.8765],\n",
      "        ...,\n",
      "        [-0.8503, -0.1056,  0.1094,  ..., -0.5892, -0.1623,  0.8949],\n",
      "        [-0.8013, -0.2299,  0.5278,  ..., -0.5406, -0.2804,  0.8734],\n",
      "        [-0.8057, -0.0311,  0.2751,  ..., -0.7054, -0.1677,  0.8904]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3000 [00:09<3:36:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.5106,  0.2307,  0.4182,  ..., -0.4790,  0.0035, -0.7862],\n",
      "         [-0.4735,  0.2913,  0.2804,  ..., -0.4450,  0.0165, -0.4992],\n",
      "         [-0.4569,  0.0236,  0.3113,  ..., -0.7188,  0.2208, -0.5913],\n",
      "         ...,\n",
      "         [-0.3639,  0.2911,  0.2655,  ..., -0.5514,  0.1282, -0.6637],\n",
      "         [-0.4132,  0.3662,  0.1953,  ..., -0.4218, -0.0139, -0.7560],\n",
      "         [-0.1363,  0.2538,  0.1911,  ..., -0.4529,  0.0788, -0.5026]],\n",
      "\n",
      "        [[-0.3934,  0.2196,  0.2120,  ..., -0.4150, -0.0448, -0.6392],\n",
      "         [-0.5309,  0.1935,  0.0425,  ..., -0.4986,  0.0277, -0.6323],\n",
      "         [-0.4116,  0.3324,  0.2659,  ..., -0.6163, -0.0515, -0.8130],\n",
      "         ...,\n",
      "         [-0.3075,  0.2302,  0.2688,  ..., -0.5912, -0.0263, -0.5214],\n",
      "         [-0.4851,  0.2677,  0.3137,  ..., -0.2891, -0.0877, -0.7322],\n",
      "         [-0.3546,  0.2073,  0.2900,  ..., -0.5685, -0.0307, -0.8269]],\n",
      "\n",
      "        [[-0.4754,  0.2283,  0.2421,  ..., -0.6157,  0.1015, -0.6064],\n",
      "         [-0.3028,  0.2622,  0.0687,  ..., -0.3301, -0.0248, -0.1337],\n",
      "         [-0.4923,  0.1502,  0.2168,  ..., -0.4677, -0.1163, -0.6096],\n",
      "         ...,\n",
      "         [-0.3242,  0.2792,  0.2433,  ..., -0.4590, -0.0489, -0.4877],\n",
      "         [-0.2632,  0.2207,  0.0298,  ..., -0.4778, -0.1267, -0.1574],\n",
      "         [-0.4342,  0.4578,  0.3596,  ..., -0.6018, -0.1291, -0.8086]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5108,  0.2206,  0.1940,  ..., -0.4208,  0.0533, -0.6304],\n",
      "         [-0.4183,  0.2321,  0.1502,  ..., -0.6610, -0.1001, -0.6112],\n",
      "         [-0.1208,  0.3403,  0.0166,  ..., -0.4861,  0.0170, -0.6603],\n",
      "         ...,\n",
      "         [-0.4584,  0.2021,  0.0958,  ..., -0.4111, -0.0353, -0.5656],\n",
      "         [-0.3493,  0.2417,  0.0510,  ..., -0.5562,  0.0872, -0.0216],\n",
      "         [-0.5378,  0.2323,  0.2321,  ..., -0.5784, -0.0167, -0.6263]],\n",
      "\n",
      "        [[-0.3315,  0.3097,  0.2625,  ..., -0.6068, -0.0097, -0.6004],\n",
      "         [-0.1058,  0.2340,  0.0755,  ..., -0.4283, -0.0949, -0.5394],\n",
      "         [-0.3973,  0.3496,  0.3974,  ..., -0.6655,  0.0539, -0.8127],\n",
      "         ...,\n",
      "         [-0.4376,  0.3960,  0.0386,  ..., -0.5317, -0.0700, -0.6245],\n",
      "         [-0.3428,  0.3717,  0.2206,  ..., -0.3292, -0.0327, -0.1737],\n",
      "         [-0.3727,  0.2337,  0.1153,  ..., -0.5177, -0.1122, -0.4559]],\n",
      "\n",
      "        [[-0.4368,  0.1718,  0.1920,  ..., -0.7298,  0.0428, -0.6561],\n",
      "         [-0.3630,  0.1847,  0.2723,  ..., -0.5486, -0.1235, -0.8027],\n",
      "         [-0.3972,  0.2524,  0.2251,  ..., -0.5524,  0.0385, -0.6035],\n",
      "         ...,\n",
      "         [-0.4888,  0.3229,  0.2732,  ..., -0.5773, -0.0036, -0.6400],\n",
      "         [-0.3860,  0.2261,  0.1556,  ..., -0.3560, -0.0137, -0.5921],\n",
      "         [-0.2846,  0.2991,  0.2327,  ..., -0.5731, -0.0647, -0.5931]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8480,  0.0490,  0.9788,  ...,  0.7094, -0.4471,  0.9934],\n",
      "        [-0.7873, -0.0958,  0.9696,  ...,  0.7181, -0.4877,  0.9783],\n",
      "        [-0.7534, -0.0773,  0.9399,  ...,  0.6333, -0.4846,  0.9772],\n",
      "        ...,\n",
      "        [-0.7988, -0.0384,  0.9583,  ...,  0.6941, -0.5317,  0.9803],\n",
      "        [-0.8391, -0.0849,  0.9478,  ...,  0.6259, -0.4948,  0.9842],\n",
      "        [-0.7642, -0.0232,  0.9559,  ...,  0.6932, -0.4539,  0.9750]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3000 [00:15<4:00:40,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.3236e-01, -1.2858e-01, -8.5733e-02,  ...,  7.4365e-02,\n",
      "           3.4285e-01, -7.1154e-01],\n",
      "         [-1.0660e-01, -1.2485e-01,  1.2212e-02,  ...,  3.0618e-01,\n",
      "           6.2294e-01, -7.2592e-01],\n",
      "         [ 9.1593e-02, -3.1201e-02, -1.9815e-01,  ...,  1.3373e-01,\n",
      "           7.0032e-01, -5.9425e-01],\n",
      "         ...,\n",
      "         [ 1.9110e-01, -2.0945e-01, -7.5123e-02,  ...,  7.3915e-02,\n",
      "           4.8619e-01, -6.7490e-01],\n",
      "         [ 1.1539e-01, -2.9408e-01, -1.2366e-02,  ...,  2.8366e-02,\n",
      "           6.0603e-01, -5.5437e-01],\n",
      "         [ 2.1291e-02, -1.9263e-01, -7.2525e-03,  ...,  1.7899e-01,\n",
      "           5.6406e-01, -6.4944e-01]],\n",
      "\n",
      "        [[-4.7534e-02, -2.2609e-02, -2.2521e-01,  ..., -2.3097e-01,\n",
      "           5.7376e-01, -2.3188e-01],\n",
      "         [ 1.0828e-01,  2.4911e-02,  7.8951e-03,  ...,  2.5623e-02,\n",
      "           6.4471e-01, -7.2866e-01],\n",
      "         [ 1.7649e-01, -5.5356e-02, -2.3794e-02,  ..., -2.9597e-03,\n",
      "           5.5036e-01, -6.3943e-01],\n",
      "         ...,\n",
      "         [ 6.2278e-02, -2.7177e-02, -1.3261e-01,  ...,  1.8178e-01,\n",
      "           6.0704e-01, -6.5759e-01],\n",
      "         [ 3.3739e-02, -1.4894e-03, -9.5309e-02,  ..., -1.0184e-02,\n",
      "           5.1477e-01, -7.2786e-01],\n",
      "         [ 6.7938e-02,  1.3279e-02, -1.0829e-01,  ..., -4.5610e-04,\n",
      "           3.8180e-01, -6.4757e-01]],\n",
      "\n",
      "        [[-3.6706e-02, -1.6408e-01, -3.9695e-02,  ...,  3.3200e-02,\n",
      "           7.3380e-01, -2.8820e-01],\n",
      "         [ 1.1408e-01, -2.8304e-02, -4.8453e-02,  ...,  8.7821e-02,\n",
      "           5.1665e-01, -7.0028e-01],\n",
      "         [-2.3670e-02,  2.2481e-01, -1.1320e-01,  ...,  5.6011e-02,\n",
      "           6.3294e-01, -7.8747e-01],\n",
      "         ...,\n",
      "         [ 1.1803e-01, -1.1347e-01, -1.3695e-01,  ...,  1.3487e-01,\n",
      "           5.9574e-01, -8.4992e-01],\n",
      "         [ 1.2571e-01, -5.6135e-02, -9.7639e-02,  ...,  5.3348e-03,\n",
      "           5.9903e-01, -6.8193e-01],\n",
      "         [-1.4724e-01, -7.9410e-02, -6.8742e-02,  ..., -5.0497e-03,\n",
      "           6.1176e-01, -5.9965e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.2212e-01, -1.2982e-01, -2.7266e-01,  ...,  4.9837e-03,\n",
      "           5.2501e-01, -5.9093e-01],\n",
      "         [ 2.2083e-01,  4.9989e-02, -3.0299e-04,  ...,  2.2575e-01,\n",
      "           3.0493e-01, -8.7687e-01],\n",
      "         [ 6.0109e-02, -1.7621e-01,  8.9000e-02,  ...,  9.2038e-02,\n",
      "           4.6171e-01, -5.5321e-01],\n",
      "         ...,\n",
      "         [ 2.3975e-01,  1.2022e-01, -8.1981e-02,  ...,  4.4450e-02,\n",
      "           5.4379e-01, -4.8079e-01],\n",
      "         [ 2.8311e-01,  7.1378e-02, -4.6496e-03,  ...,  1.2066e-01,\n",
      "           4.8813e-01, -6.9948e-01],\n",
      "         [ 7.9986e-02,  1.4879e-01, -1.2105e-01,  ..., -2.3320e-01,\n",
      "           2.9895e-01, -6.5987e-01]],\n",
      "\n",
      "        [[ 1.5669e-01,  5.5334e-02,  9.2978e-02,  ...,  1.9677e-02,\n",
      "           4.3215e-01, -6.6781e-01],\n",
      "         [ 1.3990e-01, -3.0204e-01, -1.1840e-01,  ..., -1.2071e-01,\n",
      "           5.4517e-01, -6.5891e-01],\n",
      "         [ 9.8177e-03,  7.9713e-02,  8.3205e-03,  ...,  1.6491e-01,\n",
      "           3.9227e-01, -9.4491e-01],\n",
      "         ...,\n",
      "         [-3.2608e-04, -1.8054e-02, -1.6986e-01,  ...,  1.4471e-02,\n",
      "           5.5834e-01, -6.7734e-01],\n",
      "         [ 1.4283e-01, -7.4098e-02, -2.1183e-01,  ...,  7.9134e-04,\n",
      "           5.1821e-01, -6.8827e-01],\n",
      "         [ 5.5885e-02, -6.6678e-02, -8.4508e-02,  ...,  8.8912e-02,\n",
      "           4.1245e-01, -5.8052e-01]],\n",
      "\n",
      "        [[ 7.5372e-02, -2.2399e-01,  1.9889e-02,  ..., -1.6510e-01,\n",
      "           2.2929e-01, -4.2561e-01],\n",
      "         [ 2.8537e-02,  1.3537e-01,  1.2578e-02,  ...,  1.9308e-01,\n",
      "           1.2654e-01, -3.7325e-01],\n",
      "         [ 2.1892e-02, -3.3661e-02, -1.6647e-01,  ..., -2.5127e-02,\n",
      "           6.0926e-01, -5.4959e-01],\n",
      "         ...,\n",
      "         [ 1.1529e-01, -5.1725e-02, -1.7654e-01,  ..., -8.7311e-02,\n",
      "           4.6007e-01, -5.6525e-01],\n",
      "         [ 1.2794e-02, -3.1476e-01, -1.2113e-01,  ...,  6.2726e-03,\n",
      "           5.2502e-01, -6.0988e-01],\n",
      "         [ 1.1676e-02,  7.9586e-02, -2.4400e-01,  ..., -6.6767e-02,\n",
      "           6.5314e-01, -5.3727e-01]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8527, -0.3678,  0.8608,  ...,  0.3667, -0.5478,  0.9737],\n",
      "        [-0.8210, -0.3420,  0.8134,  ...,  0.2279, -0.5265,  0.9741],\n",
      "        [-0.8155, -0.3706,  0.8793,  ...,  0.4877, -0.6000,  0.9739],\n",
      "        ...,\n",
      "        [-0.8320, -0.3672,  0.8096,  ...,  0.3307, -0.5889,  0.9661],\n",
      "        [-0.8382, -0.3810,  0.9176,  ...,  0.4757, -0.5921,  0.9804],\n",
      "        [-0.8178, -0.3933,  0.8839,  ...,  0.2669, -0.5018,  0.9705]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9936/2584204843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtotal_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\ciril\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "# Пример обучения модели\n",
    "for epoch in range(num_epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch, num_epochs))\n",
    "    print(\" Run train...\")\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    losses = []\n",
    "    #num_batches = int(120000 / 32)\n",
    "    #i = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = (batch[2] - 1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        #print(f\"===batch {i} / {num_batches}; loss={loss.item()}===\")\n",
    "        #i+=1\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\" Run validation...\")\n",
    "    model.eval()  # Переключитесь в режим оценки\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in validation_dataloader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = (batch[2] - 1).to(device)  # Перенос меток классов на GPU\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "            true_labels.extend(labels.tolist())\n",
    "            predicted_labels.extend(predicted.tolist())\n",
    "\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07921fcac9efc71e32baa62f54cc7cc7703180b766de90eef3b067ead514a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
