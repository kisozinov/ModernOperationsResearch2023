{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import inflect\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.getcwd() + \"/\" + \"nlp-lab-dm23/train_processed.csv\")\n",
    "test_df = pd.read_csv(os.getcwd() + \"/\" + \"nlp-lab-dm23/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>7595</td>\n",
       "      <td>Around the world</td>\n",
       "      <td>Ukrainian presidential candidate Viktor Yushch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>7596</td>\n",
       "      <td>Void is filled with Clement</td>\n",
       "      <td>With the supply of attractive pitching options...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>7597</td>\n",
       "      <td>Martinez leaves bitter</td>\n",
       "      <td>Like Roger Clemens did almost exactly eight ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>7598</td>\n",
       "      <td>5 of arthritis patients in Singapore take Bext...</td>\n",
       "      <td>SINGAPORE : Doctors in the United States have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>7599</td>\n",
       "      <td>EBay gets into rentals</td>\n",
       "      <td>EBay plans to buy the apartment and home renta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              Title  \\\n",
       "0        0                  Fears for T N pension after talks   \n",
       "1        1  The Race is On: Second Private Team Sets Launc...   \n",
       "2        2      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3        3      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4        4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "...    ...                                                ...   \n",
       "7595  7595                                   Around the world   \n",
       "7596  7596                        Void is filled with Clement   \n",
       "7597  7597                             Martinez leaves bitter   \n",
       "7598  7598  5 of arthritis patients in Singapore take Bext...   \n",
       "7599  7599                             EBay gets into rentals   \n",
       "\n",
       "                                            Description  \n",
       "0     Unions representing workers at Turner   Newall...  \n",
       "1     SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2     AP - A company founded by a chemistry research...  \n",
       "3     AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4     AP - Southern California's smog-fighting agenc...  \n",
       "...                                                 ...  \n",
       "7595  Ukrainian presidential candidate Viktor Yushch...  \n",
       "7596  With the supply of attractive pitching options...  \n",
       "7597  Like Roger Clemens did almost exactly eight ye...  \n",
       "7598  SINGAPORE : Doctors in the United States have ...  \n",
       "7599  EBay plans to buy the apartment and home renta...  \n",
       "\n",
       "[7600 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = inflect.engine()\n",
    "\n",
    "def lowercase_text(text):\n",
    "  return text.lower()\n",
    "\n",
    "def remove_nums(text):\n",
    "  return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def replace_nums(text):\n",
    "  # split strings into list of texts\n",
    "  temp_string = text.split()\n",
    "  # initialise empty list\n",
    "  new_str = []\n",
    "\n",
    "  for word in temp_string:\n",
    "      # if text is a digit, convert the digit\n",
    "      # to numbers and append into the new_str list\n",
    "      if word.isdigit():\n",
    "          temp = q.number_to_words(word)\n",
    "          new_str.append(temp)\n",
    "      # append the texts as it is\n",
    "      else:\n",
    "          new_str.append(word)\n",
    "\n",
    "  # join the texts of new_str to form a string\n",
    "  temp_str = ' '.join(new_str)\n",
    "  return temp_str\n",
    "\n",
    "def remove_punct(text):\n",
    "  translator = str.maketrans('', '', string.punctuation)\n",
    "  return text.translate(translator)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  stop_words = set(stopwords.words(\"english\"))\n",
    "  word_tokens = word_tokenize(text)\n",
    "  filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "  return filtered_text\n",
    "\n",
    "def full_preprocessing_pipeline(df: DataFrame):\n",
    "  res = []\n",
    "  for i, row in tqdm(df.iterrows()):\n",
    "    res.append(\n",
    "      remove_stopwords(\n",
    "        remove_punct(\n",
    "          remove_nums(\n",
    "            lowercase_text(\n",
    "                row[2]\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120000it [00:45, 2625.90it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = full_preprocessing_pipeline(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hard',\n",
       " 'overstate',\n",
       " 'sense',\n",
       " 'shock',\n",
       " 'across',\n",
       " 'much',\n",
       " 'europe',\n",
       " 'popular',\n",
       " 'mandate',\n",
       " 'americans',\n",
       " 'given',\n",
       " 'george',\n",
       " 'w',\n",
       " 'bush',\n",
       " 'even',\n",
       " 'result',\n",
       " 'great',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [15:25<00:00, 129.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(texts):\n",
    "  stemmed_text = []\n",
    "  for text in tqdm(texts):\n",
    "    stemmed_text.append([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text])\n",
    "  return stemmed_text\n",
    "texts_lem = lemmatize_words(preprocessed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(text):\n",
    "    t = remove_stopwords(\n",
    "        remove_punct(\n",
    "          remove_nums(\n",
    "            lowercase_text(\n",
    "                text\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in t])\n",
    "\n",
    "train_df[\"Description\"] = train_df[\"Description\"].apply(lambda x: preprocess_sample(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>We Have To Talk</td>\n",
       "      <td>hard overstate sense shock across much europe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Boss, Pedro talk shop</td>\n",
       "      <td>sometimes george steinbrenner negotiate tuesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Crawford leads way as US goes 1-2-3 in 200m</td>\n",
       "      <td>finish partisan greek crowd want see shawn cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Ajax Amsterdam 0-1 Juventus: FT Report</td>\n",
       "      <td>amsterdam september champion league moment bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Krispy Kreme SEC probe widens</td>\n",
       "      <td>krispy kreme doughnut inc say friday inform se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>119995</td>\n",
       "      <td>2</td>\n",
       "      <td>A bit of a head-scratcher</td>\n",
       "      <td>many professional league recently defend champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>119996</td>\n",
       "      <td>2</td>\n",
       "      <td>Fans Learning to Make Do Without NHL (AP)</td>\n",
       "      <td>ap nhl disappear right eye reason simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>119997</td>\n",
       "      <td>2</td>\n",
       "      <td>Can Arroyo help Red Sox finally get a win?</td>\n",
       "      <td>curt schilling pedro martinez bring boston red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>119998</td>\n",
       "      <td>2</td>\n",
       "      <td>Woods May Stay No. 1 - for Now (AP)</td>\n",
       "      <td>ap stewart cink atop leaderboard david tom lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>119999</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed reaction to killing of Veerappan</td>\n",
       "      <td>chennai oct pti kill forest brigand veerappan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Class Index                                        Title  \\\n",
       "0                0            1                              We Have To Talk   \n",
       "1                1            2                        Boss, Pedro talk shop   \n",
       "2                2            2  Crawford leads way as US goes 1-2-3 in 200m   \n",
       "3                3            2       Ajax Amsterdam 0-1 Juventus: FT Report   \n",
       "4                4            3                Krispy Kreme SEC probe widens   \n",
       "...            ...          ...                                          ...   \n",
       "119995      119995            2                    A bit of a head-scratcher   \n",
       "119996      119996            2    Fans Learning to Make Do Without NHL (AP)   \n",
       "119997      119997            2   Can Arroyo help Red Sox finally get a win?   \n",
       "119998      119998            2          Woods May Stay No. 1 - for Now (AP)   \n",
       "119999      119999            1       Mixed reaction to killing of Veerappan   \n",
       "\n",
       "                                              Description  \n",
       "0       hard overstate sense shock across much europe ...  \n",
       "1       sometimes george steinbrenner negotiate tuesda...  \n",
       "2       finish partisan greek crowd want see shawn cra...  \n",
       "3       amsterdam september champion league moment bri...  \n",
       "4       krispy kreme doughnut inc say friday inform se...  \n",
       "...                                                   ...  \n",
       "119995  many professional league recently defend champ...  \n",
       "119996           ap nhl disappear right eye reason simple  \n",
       "119997  curt schilling pedro martinez bring boston red...  \n",
       "119998  ap stewart cink atop leaderboard david tom lea...  \n",
       "119999  chennai oct pti kill forest brigand veerappan ...  \n",
       "\n",
       "[120000 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[\"Class Index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # \"cuda:0\" if torch.cuda.is_available() else \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train_df.Description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  hard overstate sense shock across much europe popular mandate american give george w bush even result great surprise\n",
      "Tokenized:  ['hard', 'overs', '##tate', 'sense', 'shock', 'across', 'much', 'europe', 'popular', 'mandate', 'american', 'give', 'george', 'w', 'bush', 'even', 'result', 'great', 'surprise']\n",
      "Token IDs:  [2524, 15849, 12259, 3168, 5213, 2408, 2172, 2885, 2759, 11405, 2137, 2507, 2577, 1059, 5747, 2130, 2765, 2307, 4474]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', texts[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(texts[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(texts[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  211\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in texts:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  hard overstate sense shock across much europe popular mandate american give george w bush even result great surprise\n",
      "Token IDs: tensor([  101,  2524, 15849, 12259,  3168,  5213,  2408,  2172,  2885,  2759,\n",
      "        11405,  2137,  2507,  2577,  1059,  5747,  2130,  2765,  2307,  4474,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every tweet...\n",
    "for text in texts:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_len,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "labels = torch.tensor(train_labels)\n",
    "#labels.apply_(lambda x: x-1).to(device)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96,000 training samples\n",
      "24,000 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "#val_size = int(0.2 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertTextClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertTextClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        self.activ = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        # print(outputs)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return self.activ(logits)\n",
    "\n",
    "# Пример создания модели\n",
    "num_classes = 4\n",
    "model = BertTextClassifier(model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTextClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (activ): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 0 / 3 ========\n",
      " Run train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [04:50<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.39\n",
      " Run validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:21<00:00, 34.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.20\n",
      "======== Epoch 1 / 3 ========\n",
      " Run train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [04:51<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.39\n",
      " Run validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:21<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.19\n",
      "======== Epoch 2 / 3 ========\n",
      " Run train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 574/3000 [00:55<03:53, 10.39it/s]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 3\n",
    "\n",
    "# Пример обучения модели\n",
    "for epoch in range(num_epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch, num_epochs))\n",
    "    print(\" Run train...\")\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    losses = []\n",
    "    #num_batches = int(120000 / 32)\n",
    "    #i = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = (batch[2] - 1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)  \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        #print(f\"===batch {i} / {num_batches}; loss={loss.item()}===\")\n",
    "        #i+=1\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\" Run validation...\")\n",
    "    model.eval()  # Переключитесь в режим оценки\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_dataloader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = (batch[2] - 1).to(device)  # Перенос меток классов на GPU\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "            true_labels.extend(labels.tolist())\n",
    "            predicted_labels.extend(predicted.tolist())\n",
    "\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novoe nachalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(train_df['Description'], train_df['Class Index'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=train_df['Class Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)\n",
    "max_seq_len = max(seq_len)\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "if max_seq_len>512:\n",
    "    max_seq_len = 512\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: tensor([4, 4, 4,  ..., 4, 1, 3])\n",
      "val_y: tensor([1, 2, 2,  ..., 1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "print(\"train_y:\",train_y)\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "print(\"val_y:\",val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  3103, 12702,  ...,     0,     0,     0],\n",
       "         [  101,  9706, 24890,  ...,     0,     0,     0],\n",
       "         [  101, 18286,  4357,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  1057,  2250,  ...,     0,     0,     0],\n",
       "         [  101,  3481,  6063,  ...,     0,     0,     0],\n",
       "         [  101, 26665,  1057,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([4, 4, 4,  ..., 4, 1, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert,label_map):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,len(label_map))\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        #pass the inputs to the model \n",
    "        outputs = self.bert(sent_id, attention_mask=mask)\n",
    "        cls_hs = outputs.last_hidden_state[:, 0, :]#outputs.pooler_output\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'world': 1, 'sports': 2, 'business': 3, 'sci-fi': 4}\n",
    "id2label = {1: 'world', 2: 'sports', 3: 'business', 4: 'sci-fi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert, label_map)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    total_labels =[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        # print(batch)\n",
    "        # progress update after every 50 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "        # labels.apply_(lambda x: x-1)\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model.forward(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        print(preds)\n",
    "        print(labels)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        # append the model predictions\n",
    "        total_preds+=list(preds)\n",
    "        total_labels+=labels.tolist()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "          # Calculate elapsed time in minutes.\n",
    "          #elapsed = format_time(time.time() - t0)\n",
    "\n",
    "          # Report progress.\n",
    "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            total_preds+=list(preds)\n",
    "            total_labels+=labels.tolist()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'label_map': label_map,\n",
    "        'id_map':id2label}\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 30\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m train_loss, f1_train \u001b[39m=\u001b[39m train()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#evaluate model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m valid_loss, f1_valid \u001b[39m=\u001b[39m evaluate()\n",
      "\u001b[1;32m/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m  Batch \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m  of  \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(step, \u001b[39mlen\u001b[39m(train_dataloader)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# push the batch to gpu\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m batch \u001b[39m=\u001b[39m [r\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m sent_id, mask, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# labels.apply_(lambda x: x-1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# clear previously calculated gradients \u001b[39;00m\n",
      "\u001b[1;32m/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m  Batch \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m  of  \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(step, \u001b[39mlen\u001b[39m(train_dataloader)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# push the batch to gpu\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m batch \u001b[39m=\u001b[39m [r\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m sent_id, mask, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# labels.apply_(lambda x: x-1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bkisozinov-a100-2/home/jovyan/kisozinov/ModernOperationsResearch2023/lab2/lab2_ml.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# clear previously calculated gradients \u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, f1_train = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, f1_valid = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        file_name = 'topic_saved_weights.pt'\n",
    "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
    "    print(f'Validation F1: {f1_valid:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07921fcac9efc71e32baa62f54cc7cc7703180b766de90eef3b067ead514a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
